[["Map",1,2,9,10,60,61],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.13.10","content-config-digest","d0ea88b6c980dd3c","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://vibhavmisra.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark-dimmed\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false},\"legacy\":{\"collections\":false}}","projects",["Map",11,12,29,30,46,47],"ask-vibhav-resume-chatbot",{"id":11,"data":13,"body":24,"filePath":25,"digest":26,"legacyId":27,"deferredRender":28},{"title":14,"date":15,"summary":16,"tags":17,"repo":22,"demo":23},"Ask-Vibhav Resume Chatbot",["Date","2025-04-10T00:00:00.000Z"],"A GPT-powered chatbot trained on my resume! It answers questions about my background, technical skills, education, and projects, just like an interactive CV.",[18,19,20,21],"Resume","AI","Chatbot","Groq API","https://github.com/Vibhav-Misra/AskVibhav","https://ask-vibhav.vercel.app/","◉ An interactive chatbot trained on my resume, deployed on Vercel, powered by Groq LLM API.\r\n\r\n◉ Users can ask questions about my background, skills, education, experience, or projects and get fast, on-topic answers directly from the resume.\r\n\r\n---\r\n\r\n◉ **Overview**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- Uses a fixed knowledge base (My resume text) – no need for a vector DB.\r\n- Built as a Next.js / Vercel serverless API endpoint (/api/chat).\r\n- Talks to Groq’s OpenAI-compatible Chat Completions API with modern LLaMA 3 models.\r\n- Front-end is a minimal chat UI deployed along with the backend.\r\n- The project is designed to be cheap to run (no RAG or embeddings) and simple to maintain.\r\n\r\n---\r\n\r\n◉ **Architecture & Design**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **High-Level Architecture**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n![High-Level Architecture](/images/flowcharts/flowchart2.png)\r\n\u003Cp style=\"margin-top:2rem;\">\u003C/p>\r\n\r\n---\r\n\r\n\u003Cp style=\"margin-top:2rem;\">\u003C/p>\r\n◉ **Workflow**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n```bash\r\n# 1. Clone the Repo\r\ngit clone https://github.com/your-handle/ask-vibhav.git\r\ncd ask-vibhav\r\n\r\n# 2. Install Dependencies\r\nnpm install\r\n# or\r\nyarn install\r\n\r\n# 3. Set Environment Variables\r\n# Create a .env.local file (for local dev) and add:\r\nGROQ_API_KEY=your-groq-key-here\r\n\r\n# 4. Configure Node Runtime (important on Vercel)\r\n# Either in package.json:\r\n{ \"engines\": { \"node\": \"20.x\" } }\r\n\r\n# or in vercel.json:\r\n{ \"functions\": { \"api/*.js\": { \"runtime\": \"nodejs20.x\" } } }\r\n\r\n# 5. Run Locally\r\n# open http://localhost:3000\r\nnpm run dev\r\n\r\n# 6. Deploy to Vercel\r\nvercel deploy","src/content/projects/ask-vibhav-resume-chatbot.mdx","219c01f9bbee5fa7","ask-vibhav-resume-chatbot.mdx",true,"exoplanet-habitability-explorer",{"id":29,"data":31,"body":42,"filePath":43,"digest":44,"legacyId":45,"deferredRender":28},{"title":32,"date":33,"summary":34,"tags":35,"repo":40,"demo":41},"Exoplanet Habitability Explorer",["Date","2025-09-30T00:00:00.000Z"],"Interactive exploration of 5,000+ exoplanets (NASA PSCompPars), explainable habitability score + RF classifier, presets, details drawer, and compare tray.",[36,37,38,39],"Streamlit","ML","NASA","Astrophysics","https://github.com/Vibhav-Misra/exoplanet-habitability-explorer","https://huggingface.co/spaces/VibzMiz/exoplanet-habitability-explorer","◉ An end-to-end data-science & ML project that explores, ranks, and visualizes thousands of confirmed exoplanets using data from the NASA Exoplanet Archive.\r\n\r\n◉ The project demonstrates data sourcing, feature engineering, interactive visualization, and ML classification in a single deployable web app.\r\n\r\n---\r\n\r\n◉ **Features**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **Live NASA data pull** – fetches the latest PSCompPars catalog from the NASA Exoplanet Archive via its TAP API (`src/fetch_data.py`)\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **Explainable habitability score** – composite of physical parameters such as insolation, radius, distance, stellar temperature, etc.\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **Interactive web app (Streamlit)** --\r\n  - Filter by radius, insolation, discovery year, distance, etc.\r\n  - Weight presets (Conservative HZ / Optimistic HZ / Observation-friendly) plus sliders for custom scoring\r\n  - Click-to-inspect planet details with score-component breakdown\r\n  - Compare tray for side-by-side comparison of up to 3 planets\r\n  - Downloadable filtered table\r\n  \u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **ML classifier** – trains a Random-Forest model to predict *“optimistic habitable-zone candidate”* label from non-leaking astrophysical & engineered features  \r\n  (e.g. luminosity proxy, semi-major axis, estimated insolation)\r\n  - ROC-AUC / PR-AUC / F1 displayed in the app\r\n  - Optional toggle to show predicted probability & label in the UI\r\n  \u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **Clean architecture & reproducibility** – separate training script, model artifacts in `/models`, Streamlit app in `app.py`\r\n\r\n---\r\n\r\n◉ **Tech Stack**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **Python:** `pandas`, `numpy`, `requests`, `pyarrow`\r\n- **Data science / ML:** `scikit-learn`, `joblib`\r\n- **Web app / viz:** `Streamlit`, `Plotly`, `streamlit-plotly-events`\r\n- **Data source:** NASA Exoplanet Archive TAP API\r\n\r\n---\r\n\r\n◉ **Workflow**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n```bash\r\n# 1. Create environment & install deps\r\npython3 -m venv venv\r\nsource venv/bin/activate\r\npip install -r requirements.txt\r\n\r\n# 2. Pull latest data\r\npython src/fetch_data.py\r\n\r\n# 3. (optional) Train / update ML model\r\npython src/train_classifier.py\r\n\r\n# 4. Run interactive app locally\r\nstreamlit run app.py","src/content/projects/exoplanet-habitability-explorer.mdx","f79383f43fc3f67c","exoplanet-habitability-explorer.mdx","memory-manager-for-ai-chatbot",{"id":46,"data":48,"body":56,"filePath":57,"digest":58,"legacyId":59,"deferredRender":28},{"title":49,"date":50,"summary":51,"tags":52,"repo":55},"Memory Manager for AI Chatbot",["Date","2025-07-25T00:00:00.000Z"],"Designed memory‑based personalization (episodic + semantic) over MongoDB; improved continuity and engagement.",[19,20,53,54],"MongoDB","Personalization","https://github.com/Vibhav-Misra/memory-manager-for-AI-chatbot","◉ A memory management service to allow an AI chatbot to remember conversations or user preferences.\r\n\r\n◉ This system automatically extracts, scores, and manages meaningful informationfrom conversations, creating a persistent memory system.\r\n\r\n---\r\n\r\n◉ **Features**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- Automatic memory extraction from conversations.\r\n- AI-powered scoring and decision making.\r\n- Human oversight for uncertain memories.\r\n- MongoDB storage.\r\n- Real-time processing via REST API.\r\n- Admin interface for memory review.\r\n\r\n---\r\n\r\n◉ **Architecture & Design**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n- **High-Level Architecture**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n![High-Level Architecture](/images/flowcharts/flowchart1.png)\r\n\r\n---\r\n\r\n◉ **Workflow**\r\n\u003Cp style=\"margin-top:1rem;\">\u003C/p>\r\n```bash\r\n# 1. Clone/Download the Project\r\n# Navigate to your desired directory\r\ncd /path/to/your/project\r\n\r\n# 2. Install Python Dependencies\r\n# Install all required packages\r\npip install -r requirements.txt\r\n\r\n# 3. Start MongoDB\r\n# On macOS/Linux:\r\nmongod\r\n\r\n# On Windows:\r\n\"C:\\Program Files\\MongoDB\\Server\\8.0\\bin\\mongod.exe\"\r\n\r\n# 4. Create Environment Configuration\r\n# Run the startup script (creates .env file)\r\npython run_service.py\r\n\r\n# 5. Verify Installation\r\n# Test if the service can start\r\npython test_service.py\r\n\r\n# If successful, start the main service\r\npython run_service.py\r\n\r\n# 6. Start Admin Interface (Optional)\r\n# In a new terminal\r\nstreamlit run admin_ui.py","src/content/projects/memory-manager-for-AI-chatbot.mdx","387907b0873f02d0","memory-manager-for-AI-chatbot.mdx","blog",["Map",62,63,72,73],"hello-world",{"id":62,"data":64,"body":68,"filePath":69,"digest":70,"legacyId":71,"deferredRender":28},{"title":65,"date":66,"description":67},"Hello, World",["Date","2025-10-01T04:00:00.000Z"],"Why I tore down my old portfolio and rebuilt it with Astro, Tailwind, and MDX.","Welcome to the new site!  \r\n\r\nFor a while my old portfolio felt… like a college dorm room. It worked, but it was cramped, messy, and every time I wanted to add a new project I had to shove another box into the corner. It was time for an upgrade.\r\n\r\n## Why rebuild (again)?\r\n\r\nTwo reasons:\r\n\r\n1. **Flexibility.** I wanted a place where I could post not just polished projects but also share jupyter noteboks, code snippets, visualizations and also write blogs.\r\n2. **Modern stack.** I’d been curious about Astro and wanted to see how it feels to build a site that’s fast, simple to deploy, and friendly to both static and dynamic content.\r\n\r\n## Stack choices \r\n\r\n- **Astro** -> For its island architecture and smooth content collections. It lets me write blog posts in MDX and render project cards without fighting a huge frontend framework.\r\n- **Tailwind CSS** -> I used to write custom CSS for everything; now I just sprinkle utility classes and focus on layout and design.\r\n- **MDX** -> Because plain Markdown is great… until you want to drop in a chart or a custom React component. MDX keeps things flexible.\r\n\r\nI also wired up content collections so blog posts and project pages can live alongside their data, which means no more copy-pasting routes or templates.\r\n\r\n## What you’ll find here\r\n\r\nI’ll be using this space to:\r\n- Share write-ups of data science projects (with code, visuals, and even the mistakes I made).\r\n- Post notebooks or EDA walkthroughs that deserve more explanation than a README.\r\n- Occasionally write about tools, workflows, or just what I’m learning.\r\n\r\nThe goal is to make this site feel more like a working lab notebook than a static resume.\r\n\r\nUntil then, thanks for stopping by.  \r\nIf something looks broken, that’s probably just me tinkering again, so please bear with me :)\r\n\r\n~Vibhav","src/content/blog/hello-world.mdx","c2862288258a2cae","hello-world.mdx","data-sources",{"id":72,"data":74,"body":78,"filePath":79,"digest":80,"legacyId":81,"deferredRender":28},{"title":75,"date":76,"description":77},"Where I Find My Data",["Date","2025-10-05T04:00:00.000Z"],"A curated list of all the data sources that I use for my EDA, ML, and visualization experiments.","Hey there!\r\n\r\nThroughout my studies, my professors have always emphasized the importance of choosing the right data source for any project, it can shape the entire outcome of a data science workflow.\r\n\r\nData often accounts for about 70% of a project’s predictive power, while the model contributes the remaining 30%. In other words, a strong dataset is crucial.\r\n\r\nSo, for this blog post, I decided to share some of the data sources I use most often in my projects, from classic repositories to a few niche finds.\r\n\r\n1) Kaggle Datasets - https://www.kaggle.com/datasets\r\n\r\n- Anyone who has worked with data is probably familiar with Kaggle. I find myself coming back to it regularly, whether for class projects or just exploring for future ideas.\r\n- For each dataset, you’ll often find user-contributed notebooks, EDA reports, ML models, and visualizations which really helps a lot!\r\n\r\n2) UC Irvine Machine Learning Repository - https://archive-beta.ics.uci.edu/\r\n\r\n- A classic collection of datasets, domain theories, and data generators used for decades by the ML community. \r\n- It has been widely used by students, educators, and researchers all over the world as a primary source of machine learning datasets.\r\n\r\n3) Registry of Open Data on AWS - https://registry.opendata.aws/\r\n\r\n- Helps people discover and share datasets stored on AWS.\r\n- When data is shared on AWS, anyone can analyze it and build services on top of it using a broad range of compute and data analytics products, including Amazon EC2, Amazon Athena, AWS Lambda, and Amazon EMR. Sharing data in the cloud lets data users spend more time on data analysis rather than data acquisition.\r\n- You can also submit your own project and may even get featured.\r\n\r\n4) Google Dataset Search - https://datasetsearch.research.google.com/\r\n\r\n- A search engine for datasets across thousands of web repositories.\r\n- Great for quick discovery when you have a specific topic in mind.\r\n\r\n5) Microsoft Research Open Data - https://www.microsoft.com/en-us/research/tools/\r\n\r\n- An index of datasets, SDKs, APIs, and open-source tools developed by Microsoft researchers.\r\n- Particularly useful for academic and research-oriented projects.\r\n\r\n6) Github: awesome-public-datasets - https://github.com/awesomedata/awesome-public-datasets\r\n\r\n- A community-curated list of topic-specific public datasets, collected and tidied from blogs, answers, and user responses. \r\n- Most are free, and it’s a great place to stumble upon something unexpected.\r\n\r\n7) Open Government Data Platform (OGD) India - https://www.data.gov.in/\r\n\r\n- Hosted by the National Informatics Centre (NIC) under India’s Ministry of Electronics & IT.\r\n- Contains a wide range of datasets from Indian government sources.\r\n\r\n8) U.S. Government's Open Data - https://data.gov/\r\n\r\n- The U.S. federal government’s central open data hub.\r\n- Includes everything from demographic data to environmental, health, and economic datasets.\r\n\r\n9) OpenDataNI - https://www.opendatani.gov.uk/\r\n\r\n- Features datasets from public-sector organizations in Northern Ireland.\r\n\r\n10) The official portal for European data - https://data.europa.eu/en\r\n\r\n- A single access point for open data from across the EU, from international, national, regional, local and geodata portals. \r\n\r\n11) Airbnb Data Portal - https://www.airroi.com/data-portal/\r\n\r\n- One of my most interesting finds.\r\n- Offers comprehensive Airbnb data worldwide through downloadable datasets and real-time API endpoints — great for market analysis and ROI studies.\r\n\r\nData sources can make or break a project. Exploring them not only sparks new project ideas but also gives you a better sense of the data’s quality and context.\r\n\r\nIf you have a favorite source I missed, I’d love to hear about it!\r\n\r\n\r\n~Vibhav","src/content/blog/data-sources.mdx","1d243a1f6136408f","data-sources.mdx"]